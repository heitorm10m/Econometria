{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criado por: Vinícius de Almeida Nery Ferreira (ECO - UnB)\n",
    "\n",
    "#######################################################################################################################\n",
    "###COMO USAR AS FUNÇÕES EM UM NOTEBOOK\n",
    "##Antes, copie e cole todos os imports e definições daqui na primeira célula do notebook e pressione Shift + Enter\n",
    "##Para coletar os dados do arquivo \"carros.dta\" (só funciona com arquivos .dta):\n",
    "#coletar_dados(\"carros\")\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "#%%\n",
    "##Importando os pacotes e módulos necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#Para Regressão Linear Simples e Teste F\n",
    "from scipy import stats\n",
    "#Para Regressão Linear Múltipla (OLS, GLS e WLS) e Testes Estatísticos\n",
    "import statsmodels.api as sm\n",
    "import econtools\n",
    "import econtools.metrics as mt\n",
    "\n",
    "#Pacotes para gráficos (caso precise)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Pacotes para fazer a coleta dos dados armazenados no mesmo diretório e outros pacotes gerais\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "##Criando as Funções\n",
    "def coletar_dados(nome = \"\"):\n",
    "    '''\n",
    "    Função que le os arquivos do Stata (.dta) - NÃO COLOQUE A EXTENSÃO NA HORA DE NOMEAR O \"NOME\"!\n",
    "    O arquivo deve estar na mesma pasta do arquivo de Python ou do notebook do jupyter.\n",
    "    Deixe em branco para ler o arquivo mais recentemente adicionado à pasta.\n",
    "    '''\n",
    "\n",
    "    global df\n",
    "\n",
    "    #Pegando qual a pasta do arquivo que está sendo usado pra programar\n",
    "    caminho = pathlib.Path().absolute()\n",
    "\n",
    "    #checando se o nome foi inserido ou não; caso não, pegar o arquivo .dta mais recente\n",
    "    if nome == \"\":\n",
    "        arquivo = max(glob.glob(f\"{str(caminho)}/*.dta\"), key=os.path.getctime)\n",
    "        df = pd.read_stata(arquivo)\n",
    "        print(f\"{arquivo}.dta foi lido com sucesso!\")\n",
    "        return df\n",
    "    else:\n",
    "        try:\n",
    "            arquivo = f\"{str(caminho)}/{str(nome)}.dta\"\n",
    "            df = pd.read_stata(arquivo)\n",
    "            print(f\"{nome}.dta foi lido com sucesso!\")\n",
    "            return df\n",
    "        except: #caso não tenha sido encontrado o arquivo com o nome inserido\n",
    "            print('''\n",
    "            Não foi possível achar o arquivo :(\\n\n",
    "            Verifique se seu nome está correto (sem a extensão) e se ele está no mesmo diretório do programa!\n",
    "            ''')\n",
    "\n",
    "def Regressão_Simples(Lista_x, Lista_y):\n",
    "    '''\n",
    "    Função que calcula as estatísticas de uma regressão simples\n",
    "\n",
    "    Lista_x: lista com os valores de x;\n",
    "    Lista_y: lista com os valores de y;\n",
    "    '''\n",
    "\n",
    "    global Lista_ychapeu_simples, Resíduos_simples\n",
    "    \n",
    "    #calculando o número de observações e as médias\n",
    "    Número_de_Observações = len(Lista_x)\n",
    "    Média_x = sum(Lista_x)/Número_de_Observações\n",
    "    Média_y = sum(Lista_y)/Número_de_Observações\n",
    "\n",
    "    #Calculando os coeficientes do modelo\n",
    "    B1, B0, R, valor_P, DP = stats.linregress(Lista_x, Lista_y)\n",
    "    #Gerando os valores previstos\n",
    "    Lista_ychapeu_simples = [round(B0 + B1 * i,3) for i in Lista_x]\n",
    "    #Calculando os Resíduos\n",
    "    Resíduos_simples = [(j - k) for j,k in zip(Lista_y, Lista_ychapeu_simples)]\n",
    "    \n",
    "    #Calculando R-quadrados e a Soma dos Quadrados das Variáveis\n",
    "    R_quadrado = round(R**2,5)\n",
    "    SQTx = sum([(i - Média_x)**2 for i in Lista_x])\n",
    "    SQTy = sum([(i - Média_y)**2 for i in Lista_y])\n",
    "    SQEy = sum([(i - Média_y)**2 for i in Lista_ychapeu_simples])\n",
    "    SQR = sum([i**2 for i in Resíduos_simples]) \n",
    "\n",
    "    #Calculando a Variância da Regressão e dos  Coeficientes\n",
    "    VarianciaReg = SQR/(Número_de_Observações - 2)\n",
    "    EPR = math.sqrt(VarianciaReg)\n",
    "    VarB1 = VarianciaReg/SQTx\n",
    "    VarB0 = (VarianciaReg * sum([i**2 for i in Lista_x]))/(Número_de_Observações * SQTx)\n",
    "    \n",
    "    #Calculando da estatistica t com intervalo de confiança de 95%  (p/ gerar os intervalos de confiança dos estimadores)\n",
    "    Estatistica_t_Critica = stats.t.ppf(0.95, Número_de_Observações - 2)\n",
    "\n",
    "    #Calculando os estimadores do limite inferior e superior\n",
    "    B1_inferior = B1 - math.sqrt(VarB1) * Estatistica_t_Critica\n",
    "    B1_superior = B1 + math.sqrt(VarB1) * Estatistica_t_Critica\n",
    "    B0_inferior = B0 - math.sqrt(VarB0) * Estatistica_t_Critica\n",
    "    B0_superior = B0 + math.sqrt(VarB0) * Estatistica_t_Critica\n",
    "    \n",
    "    #Gerando o Relatório\n",
    "    Relatório = f'''\n",
    "    Número de Observações = {Número_de_Observações}\\n\n",
    "    B0 = {round(B0,5)}\\t B1 = {round(B1,5)}\\t R-quadrado = {R_quadrado}\\n\n",
    "    Estimador da Variância = {round(VarianciaReg,5)}\\t Erro Padrão da Regressão = {round(EPR,5)}\\n\n",
    "    Variância de B1 = {round(VarB1,5)}\\t Variância de B0 = {round(VarB0,5)}\\n\n",
    "    Intervalo de Confiança de 95% para B1 (Inferior; B1; Superior): {round(B1_inferior,4)}; {round(B1,4)}; {round(B1_superior,4)}\\n\n",
    "    Intervalo de Confiança de 95% para B0 (Inferior; B0; Superior): {round(B0_inferior,4)}; {round(B0,4)}; {round(B0_superior,4)}\\n\n",
    "    Para ver os valores previstos, basta chamar a variável 'Lista_ychapeu_simples'\\n\n",
    "    Para ver os resíduos, chame a variável 'Resíduos_simples'\n",
    "    '''\n",
    "    print (Relatório)\n",
    "    \n",
    "    ##Criando um gráfico\n",
    "    #Deixando o estilo bonitinho\n",
    "    sns.set_style(style=\"white\")\n",
    "\n",
    "    #Criando o objeto gráfico\n",
    "    Grafico = sns.regplot(x = Lista_x, y = Lista_y, scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"})\n",
    "    Grafico.set_title(\"Resultado da Regressão\",fontsize = 11)\n",
    "    plt.show()\n",
    "\n",
    "def Regressão_Múltipla(x, y, constante = \"S\", robusta = \"N\"):\n",
    "    '''\n",
    "    Função que calcula uma regressão múltipla, sendo, por default, computada com um intercepto e com erros padrões não robustos.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    constante: \"S\" para regressão com intercepto e qualquer outro valor para sem intercepto. Caso em branco, a regressão é computada com intercepto;\n",
    "    robusta: \"N\" para regressão com erros-padrão tradicionais e qualquer outro valor para erros-padrões robustos. Caso em branco, a regressão é computada com erros-padrão comuns.\n",
    "    '''\n",
    "\n",
    "    global Resultado, Lista_ychapeu, Resíduos, SQR, EPR\n",
    "\n",
    "    #adicionando uma constante ao modelo de Ordinary Least Squares (OLS)\n",
    "    if constante == \"S\":\n",
    "        X = sm.add_constant(x)\n",
    "    else:\n",
    "        X = x\n",
    "\n",
    "    #Criando o Modelo levando em conta a opção de ser uma regressão robusta p/ heteroscedasticidade ou não\n",
    "    Modelo = sm.OLS(y,X)\n",
    "\n",
    "    if robusta == \"N\":\n",
    "        Resultado = Modelo.fit()\n",
    "    else:\n",
    "        Resultado = Modelo.fit(cov_type = 'HC1', use_t = True)\n",
    "    \n",
    "    Lista_ychapeu = Resultado.predict()\n",
    "    Resíduos = y - Lista_ychapeu\n",
    "\n",
    "    #Calculando o Erro Padrão da Regressão (EPR)\n",
    "    SQR =sum([i**2 for i in Resíduos])\n",
    "    Número_de_Observações = len(y)\n",
    "    GL = Número_de_Observações - len(Resultado.params)\n",
    "    VarianciaReg = SQR/GL\n",
    "    EPR = math.sqrt(VarianciaReg)\n",
    "    \n",
    "    ##Printando o Resultado\n",
    "    #print('Parâmetros:\\n', Resultado.params) #O primeiro resultado equivale ao intercepto\n",
    "    #print('\\nDesvios Padrões:\\n', Resultado.bse)\n",
    "    #print('Valores Previstos: ', Resultado.predict())\n",
    "    #print('\\nR2:', Resultado.rsquared)\n",
    "    print(f\"O erro padrão da regressão é {round(EPR,5)} e a SQR é {round(SQR,5)}\\n\")\n",
    "    print(Resultado.summary())\n",
    "\n",
    "    print(\"\\nPara ver os valores previstos ou os resídudos, basta chamar 'Lista_ychapeu' e 'Resíduos'.\")\n",
    "    print(\"Os resultados do modelo podem ser obtidos através de métodos usando a variável 'Resultado'.\")\n",
    "    print(\"\"\"\n",
    "    Valores de condição maiores que 20 indicam problemas de multicolinearidade\n",
    "    Para ver como achar esse número, entre em https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\"\"\"\n",
    "    )\n",
    "\n",
    "def Regressão_MQP(x, y, pesos, constante = \"S\", robusta = \"N\"):\n",
    "    '''\n",
    "    Função que calcula uma regressão múltipla usando mínimos quadrados ponderados, ou seja,\n",
    "    recomendada quando o erro é heteroscedástico E se sabe a função da constante. Ela é, por default, computada com um intercepto e com erros padrões não robustos.\n",
    "    multiplicativa da variância do erro.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    pesos: 1/h, sendo h a constante multiplicativa da variância do erro;\n",
    "    constante: \"S\" para regressão com intercepto e qualquer outro valor para sem intercepto. Caso em branco, a regressão é computada com intercepto;\n",
    "    robusta: \"N\" para regressão com erros-padrão tradicionais e qualquer outro valor para erros-padrões robustos. Caso em branco, a regressão é computada com erros-padrão comuns.\n",
    "    '''\n",
    "\n",
    "    global Resultado, Lista_ychapeu, Resíduos, SQR, EPR\n",
    "\n",
    "    #adicionando uma constante ao modelo de Ordinary Least Squares(OLS)\n",
    "    if constante == \"S\":\n",
    "        X = sm.add_constant(x)\n",
    "    else:\n",
    "        X = x\n",
    "    #Criando o Modelo levando em conta a opção de ser uma regressão robusta p/ heteroscedasticidade ou não\n",
    "    Modelo = sm.WLS(y,X, weights = pesos)\n",
    "    if robusta == \"N\":\n",
    "        Resultado = Modelo.fit()\n",
    "    else:\n",
    "        Resultado = Modelo.fit(cov_type = 'HC1', use_t = True)\n",
    "    \n",
    "    Lista_ychapeu = Resultado.predict()\n",
    "    Resíduos = y - Lista_ychapeu\n",
    "\n",
    "    #Calculando o Erro Padrão da Regressão (EPR)\n",
    "    SQR =sum([i**2 for i in Resíduos])\n",
    "    Número_de_Observações = len(y)\n",
    "    GL = Número_de_Observações - len(Resultado.params)\n",
    "    VarianciaReg = SQR/GL\n",
    "    EPR = math.sqrt(VarianciaReg)\n",
    "    \n",
    "    ##Printando o Resultado\n",
    "    print(f\"O erro padrão da regressão é {round(EPR,5)} e a SQR é {round(SQR,5)}\\n\")\n",
    "    print(Resultado.summary())\n",
    "\n",
    "    print(\"\\nPara ver os valores previstos ou os resídudos, basta chamar 'Lista_ychapeu' e 'Resíduos'.\")\n",
    "    print(\"Os resultados do modelo podem ser obtidos através de métodos usando a variável 'Resultado'.\")\n",
    "    print(\"\"\"\n",
    "    Valores de condição maiores que 20 indicam problemas de multicolinearidade\n",
    "    Para ver como achar esse número, entre em https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\"\"\"\n",
    "    )\n",
    "    \n",
    "def Regressão_MQGF(x, y, constante = \"S\", robusta = \"N\"):\n",
    "    '''\n",
    "    Função que calcula uma regressão múltipla usando mínimos quadrados generalizados factíveis, ou seja,\n",
    "    recomendada quando o erro é heteroscedástico E NÃO se sabe a função da constante multiplicativa da variância do erro, sendo os pesos estimados\n",
    "    regridindo o log dos quadrados dos resíduos sobre as variáveis explicativas. Os estimadores MQP são gerados com o peso estimado.\n",
    "    Ela é, por default, computada com um intercepto e com erros padrões não robustos.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    constante: \"S\" para regressão com intercepto e qualquer outro valor para sem intercepto. Caso em branco, a regressão é computada com intercepto;\n",
    "    robusta: \"N\" para regressão com erros-padrão tradicionais e qualquer outro valor para erros-padrões robustos. Caso em branco, a regressão é computada com erros-padrão comuns.\n",
    "    '''\n",
    "\n",
    "    global Resultado, Lista_ychapeu, Resíduos, SQR, EPR\n",
    "\n",
    "    #Regredindo os valores normalmente a fim de pegar os resíduos\n",
    "    Regressão_Múltipla(x,y, constante, robusta)\n",
    "    clear_output()\n",
    "\n",
    "    #Coletando o log dos quadrados dos resíduos\n",
    "    Log_Res_Quad = np.log(Resíduos**2)\n",
    "\n",
    "    #Regredindo Log_Res_Quad sobre as variáveis explicativas\n",
    "    Regressão_Múltipla(x,Log_Res_Quad, constante, robusta)\n",
    "    clear_output()\n",
    "\n",
    "    #Estimando os pesos\n",
    "    Pesos = np.exp(Lista_ychapeu)\n",
    "\n",
    "    #Fazendo uma Regressão MQP\n",
    "    Regressão_MQP(x,y, 1/Pesos, constante, robusta)\n",
    "\n",
    "def Teste_LM(x, y, Restrições, Nivel_de_Significância = 0.05):\n",
    "    '''\n",
    "    Função que calcula um teste LM e dá o resultado teste de hipótese para o caso de todas as restrições serem conjuntamente estatisticamente não-significantes.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    Restrições: lista ou array com os valores a serem tirados do modelo restrito;\n",
    "    Nivel_de_Significância: nível de significância do teste. Caso branco, o nível de significancia padrão é de 5%.\n",
    "    '''\n",
    "\n",
    "    ##Definindo as variáveis de cada modelo\n",
    "    ModeloIrrestrito = list(x)\n",
    "    ModeloRestrito = []\n",
    "    Restrições = list(Restrições)\n",
    "\n",
    "    Numero_de_Observações = len(y)\n",
    "    GL_ir = Numero_de_Observações - (len(ModeloIrrestrito) + 1)\n",
    "    GL_r = len(Restrições)\n",
    "\n",
    "    for i in ModeloIrrestrito:\n",
    "        if i not in Restrições:\n",
    "            ModeloRestrito.append(i)\n",
    "    \n",
    "    #Fazendo a regressão do modelo restrito e armazenando os resíduos\n",
    "    Regressão_Múltipla(df[ModeloRestrito], y)\n",
    "    Resíduos_r = Resíduos\n",
    "\n",
    "    #Fazendo a regressão dos resíduos sobre as variáveis independentes e armazenando o R2\n",
    "    Regressão_Múltipla(x, Resíduos_r)\n",
    "    Ru = Resultado.rsquared\n",
    "\n",
    "    #Calculando a estatística LM\n",
    "    LM = Numero_de_Observações*Ru\n",
    "\n",
    "    #Calculando o p-valor\n",
    "    ##Calculando o P-valor de F\n",
    "    P_valor = stats.chi2.sf(LM,GL_r)\n",
    "\n",
    "    #Limpando a tela\n",
    "    clear_output()\n",
    "\n",
    "    #Printando o resultado\n",
    "    if Nivel_de_Significância > P_valor:\n",
    "        print(f\"O valor de LM é {round(LM,3)} e seu p-valor é {round(P_valor,7)}. Portanto, rejeita-se Ho a um nível de significância de {Nivel_de_Significância*100}%.\")\n",
    "    else:\n",
    "        print(f\"O valor de LM é {round(LM,3)} e seu p-valor é {round(P_valor,7)}. Portanto, não se rejeita Ho a um nível de significância de {Nivel_de_Significância*100}%.\")\n",
    "\n",
    "\n",
    "def Teste_F(x, y, Restrições, Nivel_de_Significância = 0.05):\n",
    "    '''\n",
    "    Função que calcula um teste F e dá o resultado teste de hipótese para o caso de todas as restrições serem conjuntamente estatisticamente não-significantes.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    Restrições: lista ou array com os valores a serem tirados do modelo restrito;\n",
    "    Nivel_de_Significância: nível de significância do teste. Caso branco, o nível de significancia padrão é de 5%.\n",
    "    '''\n",
    "\n",
    "    ##Definindo as variáveis de cada modelo\n",
    "    #para testar igualdade dos coeficientes, F2, p_valueF2 = results.Ftest(['ACT', 'skipped'], equal=True)\n",
    "    ModeloIrrestrito = list(x)\n",
    "    ModeloRestrito = []\n",
    "    Restrições = list(Restrições)\n",
    "\n",
    "    Numero_de_Observações = len(y)\n",
    "    GL_ir = Numero_de_Observações - (len(ModeloIrrestrito) + 1)\n",
    "    GL_r = len(Restrições)\n",
    "\n",
    "    for i in ModeloIrrestrito:\n",
    "        if i not in Restrições:\n",
    "            ModeloRestrito.append(i)\n",
    "\n",
    "    ##Fazendo as regressões de cada modelo\n",
    "    Regressão_Múltipla(x, y)\n",
    "    SQR_ir = SQR\n",
    "    VarianciaReg_ir = EPR**2\n",
    "\n",
    "    Regressão_Múltipla(df[ModeloRestrito], y)\n",
    "    SQR_r = SQR\n",
    "\n",
    "    #Limpando a tela\n",
    "    clear_output()\n",
    "    \n",
    "    ##Calculando F\n",
    "    F = (SQR_r - SQR_ir)/(len(Restrições)*VarianciaReg_ir)\n",
    "\n",
    "    ##Calculando o P-valor de F\n",
    "    P_valor = stats.f.sf(F,GL_r,GL_ir)\n",
    "\n",
    "    if Nivel_de_Significância > P_valor:\n",
    "        print(f\"O valor de F é {round(F,3)} e seu p-valor é {round(P_valor,7)}. Portanto, rejeita-se Ho a um nível de significância de {Nivel_de_Significância*100}%.\")\n",
    "    else:\n",
    "        print(f\"O valor de F é {round(F,3)} e seu p-valor é {round(P_valor,7)}. Portanto, não se rejeita Ho a um nível de significância de {Nivel_de_Significância*100}%.\")\n",
    "\n",
    "def Teste_t_Dois_Coeficientes_Iguais(x, y, Coeficientes_Testados_para_serem_iguais, Nivel_de_Significância = 0.05):\n",
    "    '''\n",
    "    Função que executa um teste t para verificar se dois coeficientes são iguais.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    Coeficientes_Testados_para_serem_iguais: array com os valores dos coeficientes que querem ser testados;\n",
    "    Nivel_de_Significância: nível de significância do teste. Caso branco, o nível de significancia padrão é de 5%.\n",
    "    '''\n",
    "    \n",
    "    ##Fazendo a regressão do modelo irrestrito\n",
    "    Regressão_Múltipla(x, y)\n",
    "    clear_output()\n",
    "\n",
    "    #Fazendo o objeto de lista que será usado no teste\n",
    "    Teste =[0]\n",
    "    Num_de_Variaveis = 1\n",
    "\n",
    "    for i in list(x):\n",
    "        if i not in list(Coeficientes_Testados_para_serem_iguais):\n",
    "            Teste.append(0)\n",
    "        elif (Num_de_Variaveis % 2 == 0):\n",
    "            Teste.append(-1)\n",
    "        else:\n",
    "            Teste.append(1)\n",
    "            Num_de_Variaveis += 1\n",
    "\n",
    "    Teste_t = Resultado.t_test(Teste)\n",
    "    print(f\"A estatística do teste é {np.around(Teste_t.tvalue[0],3)}, o que resulta em um p-valor de {np.around(Teste_t.pvalue[0],6)}\")\n",
    "\n",
    "def Teste_Heteroscedasticidade_BP(x, y, constante = \"S\", Nivel_de_Significância = 0.05, Estatística = \"LM\"):\n",
    "    '''\n",
    "    Função que executa o teste de Breusch-Pagan para a heteroscedasticidade.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    constante: \"S\" para regressão com intercepto e qualquer outro valor para sem intercepto. Caso em branco, a regressão é computada com intercepto;\n",
    "    Nivel_de_Significância: nível de significância do teste. Caso branco, o nível de significancia padrão é de 5%.\n",
    "    Estatística = LM ou F\n",
    "    '''\n",
    "\n",
    "    #Fazendo a regressão e limpando a tela\n",
    "    Regressão_Múltipla(x,y,constante)\n",
    "    clear_output()\n",
    "\n",
    "    #Calculando o quadrado dos resíduos\n",
    "    Res_Quad = Resíduos**2\n",
    "\n",
    "    #Realizando o teste F ou LM de Res_Quad sobre as variaveis dependentes para ver se há correlação\n",
    "    if Estatística == \"LM\":\n",
    "        Teste_LM(x, Res_Quad, x, Nivel_de_Significância)\n",
    "        print(\"Ho: O erro é homoscedástico\")\n",
    "    else:\n",
    "        Teste_F(x, Res_Quad, x, Nivel_de_Significância)\n",
    "        print(\"Ho: O erro é homoscedástico\")\n",
    "\n",
    "def Teste_Heteroscedasticidade_White(x, y, constante = \"S\", Nivel_de_Significância = 0.05, Estatística = \"LM\"):\n",
    "    '''\n",
    "    Função que executa o teste de White (modificado por Wooldridge) para a heteroscedasticidade.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    constante: \"S\" para regressão com intercepto e qualquer outro valor para sem intercepto. Caso em branco, a regressão é computada com intercepto;\n",
    "    Nivel_de_Significância: nível de significância do teste. Caso branco, o nível de significancia padrão é de 5%.\n",
    "    Estatística: LM ou F\n",
    "    '''\n",
    "\n",
    "    #Fazendo a regressão e limpando a tela\n",
    "    Regressão_Múltipla(x,y,constante)\n",
    "    clear_output()\n",
    "\n",
    "    #Calculando o quadrado dos resíduos\n",
    "    Res_Quad = Resultado.resid**2\n",
    "\n",
    "    #Calculando o quadrado dos valores previstos\n",
    "    Previstos = Lista_ychapeu\n",
    "    Previstos2 = Previstos**2\n",
    "\n",
    "    #Criando um dataframe pra armazenar esses valores\n",
    "    dfy_y2 = pd.DataFrame({\"y\":Previstos,\"y2\":Previstos2})\n",
    "    y_y2 = dfy_y2[['y','y2']]\n",
    "\n",
    "    #Realizando o teste F ou LM de Res_Quad sobre y e y^2\n",
    "    if Estatística == \"LM\":\n",
    "        Teste_LM(y_y2, Res_Quad, y_y2, Nivel_de_Significância)\n",
    "        print(\"Ho: O erro é homoscedástico\")\n",
    "    else:\n",
    "        Teste_F(y_y2, Res_Quad, y_y2, Nivel_de_Significância)\n",
    "        print(\"Ho: O erro é homoscedástico\")\n",
    "\n",
    "def RESET(x, y, constante = \"S\", robusta = \"N\", Nivel_de_Significância = 0.05):\n",
    "    '''\n",
    "    Função que executa um teste RESET para verificar a adequação das formas funcionais.\n",
    "    Ho: o modelo está bem especificado.\n",
    "\n",
    "    x: lista ou array com os valores das variáveis independentes;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    constante: \"S\" para regressão com intercepto e qualquer outro valor para sem intercepto. Caso em branco, a regressão é computada com intercepto;\n",
    "    robusta: \"N\" para regressão com erros-padrão tradicionais e qualquer outro valor para erros-padrões robustos. Caso em branco, a regressão é computada com erros-padrão comuns;\n",
    "    Nivel_de_Significância: nível de significância do teste. Caso branco, o nível de significancia padrão é de 5%.\n",
    "    '''\n",
    "    #Fazendo uma regressão múltipla e limpando a tela\n",
    "    Regressão_Múltipla(x, y, constante)\n",
    "    clear_output()\n",
    "\n",
    "    #Verificando o tipo da covariância selecionada\n",
    "    if robusta == \"N\":\n",
    "        tipo = 'nonrobust'\n",
    "    else:\n",
    "        tipo = 'HC1'\n",
    "\n",
    "    Teste = sm.stats.diagnostic.linear_reset(Resultado, power = 2, use_f = False, cov_type = tipo)\n",
    "    \n",
    "    if Teste.pvalue < Nivel_de_Significância:\n",
    "        print(f\"\"\"\n",
    "        O p-valor do teste foi de {np.around(Teste.pvalue,6)}, menor que o nível de significância de {Nivel_de_Significância*100}%.\\n\n",
    "        Assim, rejeita-se Ho (o modelo está MAL especificado).\"\"\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"\"\"\n",
    "        O p-valor do teste foi de {np.around(Teste.pvalue,6)}, maior que o nível de significância de {Nivel_de_Significância*100}%.\\n\n",
    "        Assim, não se rejeita Ho (o modelo NÃO está MAL especificado)\"\"\"\n",
    "        )\n",
    "\n",
    "def Teste_J_Davidson_MacKinnon(x1,x2, y, constante = \"S\", robusta = \"N\", Nivel_de_Significância = 0.05):\n",
    "    '''\n",
    "    Função que executa um teste J para verificar qual o modelo mais adequado (dentre os dois colocados).\n",
    "    Ho: o modelo 1 é preferível (ver o p-valor do último coeficiente).\n",
    "\n",
    "    x1: lista ou array com os valores das variáveis independentes do primeiro modelo;\n",
    "    x2: lista ou array com os valores das variáveis independentes do segundo modelo;\n",
    "    y: lista ou array com os valores da variável dependente;\n",
    "    constante: \"S\" para regressão com intercepto e qualquer outro valor para sem intercepto. Caso em branco, a regressão é computada com intercepto;\n",
    "    robusta: \"N\" para regressão com erros-padrão tradicionais e qualquer outro valor para erros-padrões robustos. Caso em branco, a regressão é computada com erros-padrão comuns;\n",
    "    Nivel_de_Significância: nível de significância do teste. Caso branco, o nível de significancia padrão é de 5%.\n",
    "    '''\n",
    "    \n",
    "    #Fazendo a regressão do segundo modelo\n",
    "    Regressão_Múltipla(x2, y, constante, robusta)\n",
    "    clear_output()\n",
    "\n",
    "    #Criando um novo dataframe e adicionando os valores previstos do modelo 2 à x\n",
    "    Valores_Previstos_2 = pd.DataFrame({'Previsão M1':Lista_ychapeu})\n",
    "    x = pd.concat([x1, Valores_Previstos_2], axis=1, sort=False)\n",
    "\n",
    "    #Fazendo a regressão do primeiro modelo sobre x\n",
    "    Regressão_Múltipla(x, y, constante, robusta)\n",
    "    clear_output()\n",
    "\n",
    "    #Pegando o p-valor do teste\n",
    "    P_valor = Resultado.pvalues[-1]\n",
    "\n",
    "    if P_valor < Nivel_de_Significância:\n",
    "        print(f\"\"\"\n",
    "        O p-valor do teste foi de {np.around(P_valor,6)}, menor que o nível de significância de {Nivel_de_Significância*100}%.\\n\n",
    "        Assim, rejeita-se Ho (ou seja, o modelo 2 ({list(x2)}) é mais bem especificado).\"\"\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"\"\"\n",
    "        O p-valor do teste foi de {np.around(P_valor,6)}, menor que o nível de significância de {Nivel_de_Significância*100}%.\\n\n",
    "        Assim, não se rejeita Ho (ou seja, o modelo 1 ({list(x1)}) é mais bem especificado).\"\"\"\n",
    "        )\n"
   ]
  },
  {
   "source": [
    "# Questão 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dadosmunicipios.dta foi lido com sucesso!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      escol           pib      pop  desig    pobreza  poprural      analf  \\\n",
       "0       3.7  14649.976562  10208.0  0.632  51.840000    3450.0  20.160000   \n",
       "1       3.0  11227.611328   6730.0  0.667  58.507999    1459.0  20.412001   \n",
       "2       2.5   6927.590332   7121.0  0.542  68.810997    3638.0  25.604000   \n",
       "3       1.8  44991.011719  51090.0  0.536  81.734001   34612.0  39.916000   \n",
       "4       NaN  50836.183594  11463.0  0.653  43.911999    8463.0  22.796000   \n",
       "...     ...           ...      ...    ...        ...       ...        ...   \n",
       "5503    1.4  20115.060547  18120.0  0.582  73.195000   10169.0  42.999001   \n",
       "5504    2.6  21157.789062  31819.0  0.523  76.162003   15059.0  36.916000   \n",
       "5505    4.0  20469.505859  18945.0  0.526  54.722000       NaN  18.091999   \n",
       "5506    NaN           NaN   4883.0  0.426  76.162003    3509.0  59.862000   \n",
       "5507    2.2   7137.598145   5174.0  0.569  70.498001    2536.0  44.217999   \n",
       "\n",
       "         rural     pibpc  ne  se  su  co  no  escolne  escolse  escolsu  \\\n",
       "0     0.337970  1.435147   0   0   0   0   1      0.0      0.0      0.0   \n",
       "1     0.216790  1.668293   0   0   0   0   1      0.0      0.0      0.0   \n",
       "2     0.510883  0.972840   0   0   0   0   1      0.0      0.0      0.0   \n",
       "3     0.677471  0.880623   0   0   0   0   1      0.0      0.0      0.0   \n",
       "4     0.738288  4.434806   0   0   0   0   1      NaN      NaN      NaN   \n",
       "...        ...       ...  ..  ..  ..  ..  ..      ...      ...      ...   \n",
       "5503  0.561203  1.110103   1   0   0   0   0      1.4      0.0      0.0   \n",
       "5504  0.473271  0.664942   1   0   0   0   0      2.6      0.0      0.0   \n",
       "5505       NaN  1.080470   1   0   0   0   0      4.0      0.0      0.0   \n",
       "5506  0.718616       NaN   1   0   0   0   0      NaN      NaN      NaN   \n",
       "5507  0.490143  1.379513   1   0   0   0   0      2.2      0.0      0.0   \n",
       "\n",
       "      escolco  escolno  \n",
       "0         0.0      3.7  \n",
       "1         0.0      3.0  \n",
       "2         0.0      2.5  \n",
       "3         0.0      1.8  \n",
       "4         NaN      NaN  \n",
       "...       ...      ...  \n",
       "5503      0.0      0.0  \n",
       "5504      0.0      0.0  \n",
       "5505      0.0      0.0  \n",
       "5506      NaN      NaN  \n",
       "5507      0.0      0.0  \n",
       "\n",
       "[5508 rows x 19 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>escol</th>\n      <th>pib</th>\n      <th>pop</th>\n      <th>desig</th>\n      <th>pobreza</th>\n      <th>poprural</th>\n      <th>analf</th>\n      <th>rural</th>\n      <th>pibpc</th>\n      <th>ne</th>\n      <th>se</th>\n      <th>su</th>\n      <th>co</th>\n      <th>no</th>\n      <th>escolne</th>\n      <th>escolse</th>\n      <th>escolsu</th>\n      <th>escolco</th>\n      <th>escolno</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.7</td>\n      <td>14649.976562</td>\n      <td>10208.0</td>\n      <td>0.632</td>\n      <td>51.840000</td>\n      <td>3450.0</td>\n      <td>20.160000</td>\n      <td>0.337970</td>\n      <td>1.435147</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>11227.611328</td>\n      <td>6730.0</td>\n      <td>0.667</td>\n      <td>58.507999</td>\n      <td>1459.0</td>\n      <td>20.412001</td>\n      <td>0.216790</td>\n      <td>1.668293</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.5</td>\n      <td>6927.590332</td>\n      <td>7121.0</td>\n      <td>0.542</td>\n      <td>68.810997</td>\n      <td>3638.0</td>\n      <td>25.604000</td>\n      <td>0.510883</td>\n      <td>0.972840</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.8</td>\n      <td>44991.011719</td>\n      <td>51090.0</td>\n      <td>0.536</td>\n      <td>81.734001</td>\n      <td>34612.0</td>\n      <td>39.916000</td>\n      <td>0.677471</td>\n      <td>0.880623</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>50836.183594</td>\n      <td>11463.0</td>\n      <td>0.653</td>\n      <td>43.911999</td>\n      <td>8463.0</td>\n      <td>22.796000</td>\n      <td>0.738288</td>\n      <td>4.434806</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5503</th>\n      <td>1.4</td>\n      <td>20115.060547</td>\n      <td>18120.0</td>\n      <td>0.582</td>\n      <td>73.195000</td>\n      <td>10169.0</td>\n      <td>42.999001</td>\n      <td>0.561203</td>\n      <td>1.110103</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5504</th>\n      <td>2.6</td>\n      <td>21157.789062</td>\n      <td>31819.0</td>\n      <td>0.523</td>\n      <td>76.162003</td>\n      <td>15059.0</td>\n      <td>36.916000</td>\n      <td>0.473271</td>\n      <td>0.664942</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5505</th>\n      <td>4.0</td>\n      <td>20469.505859</td>\n      <td>18945.0</td>\n      <td>0.526</td>\n      <td>54.722000</td>\n      <td>NaN</td>\n      <td>18.091999</td>\n      <td>NaN</td>\n      <td>1.080470</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5506</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4883.0</td>\n      <td>0.426</td>\n      <td>76.162003</td>\n      <td>3509.0</td>\n      <td>59.862000</td>\n      <td>0.718616</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5507</th>\n      <td>2.2</td>\n      <td>7137.598145</td>\n      <td>5174.0</td>\n      <td>0.569</td>\n      <td>70.498001</td>\n      <td>2536.0</td>\n      <td>44.217999</td>\n      <td>0.490143</td>\n      <td>1.379513</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5508 rows × 19 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "coletar_dados(\"dadosmunicipios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4491"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#Limpando o dataset\n",
    "df.dropna(subset = ['escol'], axis = 0, inplace = True)\n",
    "#resetando o index\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O erro padrão da regressão é 8.74366 e a SQR é 342503.15107\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                pobreza   R-squared:                       0.852\n",
      "Model:                            OLS   Adj. R-squared:                  0.852\n",
      "Method:                 Least Squares   F-statistic:                     2588.\n",
      "Date:                Wed, 18 Nov 2020   Prob (F-statistic):               0.00\n",
      "Time:                        11:26:37   Log-Likelihood:                -16105.\n",
      "No. Observations:                4491   AIC:                         3.223e+04\n",
      "Df Residuals:                    4480   BIC:                         3.230e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         77.4252      0.895     86.460      0.000      75.670      79.181\n",
      "no            11.2940      1.691      6.678      0.000       7.978      14.610\n",
      "ne             9.5852      1.073      8.933      0.000       7.482      11.689\n",
      "su            -9.3504      1.721     -5.434      0.000     -12.724      -5.977\n",
      "co            -7.1024      2.235     -3.177      0.001     -11.485      -2.720\n",
      "pibpc         -0.4382      0.046     -9.424      0.000      -0.529      -0.347\n",
      "escol        -11.7969      0.237    -49.787      0.000     -12.261     -11.332\n",
      "escol_no       1.4760      0.574      2.572      0.010       0.351       2.601\n",
      "escol_ne       2.9214      0.357      8.193      0.000       2.222       3.620\n",
      "escol_su       2.1713      0.420      5.165      0.000       1.347       2.996\n",
      "escol_co       2.2700      0.619      3.668      0.000       1.057       3.483\n",
      "==============================================================================\n",
      "Omnibus:                       21.323   Durbin-Watson:                   1.985\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.686\n",
      "Skew:                           0.107   Prob(JB):                     4.36e-06\n",
      "Kurtosis:                       3.294   Cond. No.                         111.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Para ver os valores previstos ou os resídudos, basta chamar 'Lista_ychapeu' e 'Resíduos'.\n",
      "Os resultados do modelo podem ser obtidos através de métodos usando a variável 'Resultado'.\n",
      "\n",
      "    Valores de condição maiores que 20 indicam problemas de multicolinearidade\n",
      "    Para ver como achar esse número, entre em https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n"
     ]
    }
   ],
   "source": [
    "##Fazendo a regressão por MQO e sem inferência robusta\n",
    "df['escol_no'] = df['escol']*df['no']\n",
    "df['escol_ne'] = df['escol']*df['ne']\n",
    "df['escol_su'] = df['escol']*df['su']\n",
    "df['escol_co'] = df['escol']*df['co']\n",
    "\n",
    "Regressão_Múltipla(df[['no','ne','su','co','pibpc','escol','escol_no','escol_ne','escol_su','escol_co']],df['pobreza'], \"S\", \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O erro padrão da regressão é 8.74366 e a SQR é 342503.15107\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                pobreza   R-squared:                       0.852\nModel:                            OLS   Adj. R-squared:                  0.852\nMethod:                 Least Squares   F-statistic:                     3081.\nDate:                Wed, 18 Nov 2020   Prob (F-statistic):               0.00\nTime:                        11:26:37   Log-Likelihood:                -16105.\nNo. Observations:                4491   AIC:                         3.223e+04\nDf Residuals:                    4480   BIC:                         3.230e+04\nDf Model:                          10                                         \nCovariance Type:                  HC1                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         77.4252      1.433     54.035      0.000      74.616      80.234\nno            11.2940      1.991      5.672      0.000       7.391      15.197\nne             9.5852      1.509      6.352      0.000       6.627      12.544\nsu            -9.3504      2.339     -3.998      0.000     -13.936      -4.765\nco            -7.1024      2.909     -2.442      0.015     -12.806      -1.399\npibpc         -0.4382      0.098     -4.474      0.000      -0.630      -0.246\nescol        -11.7969      0.385    -30.607      0.000     -12.553     -11.041\nescol_no       1.4760      0.665      2.221      0.026       0.173       2.779\nescol_ne       2.9214      0.437      6.684      0.000       2.064       3.778\nescol_su       2.1713      0.580      3.744      0.000       1.034       3.308\nescol_co       2.2700      0.806      2.815      0.005       0.689       3.851\n==============================================================================\nOmnibus:                       21.323   Durbin-Watson:                   1.985\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               24.686\nSkew:                           0.107   Prob(JB):                     4.36e-06\nKurtosis:                       3.294   Cond. No.                         111.\n==============================================================================\n\nWarnings:\n[1] Standard Errors are heteroscedasticity robust (HC1)\n\nPara ver os valores previstos ou os resídudos, basta chamar 'Lista_ychapeu' e 'Resíduos'.\nOs resultados do modelo podem ser obtidos através de métodos usando a variável 'Resultado'.\n\n    Valores de condição maiores que 20 indicam problemas de multicolinearidade\n    Para ver como achar esse número, entre em https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n"
     ]
    }
   ],
   "source": [
    "##Fazendo a regressão por MQO e COM inferência robusta\n",
    "Regressão_Múltipla(df[['no','ne','su','co','pibpc','escol','escol_no','escol_ne','escol_su','escol_co']],df['pobreza'], \"S\", \"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SE: {'INT': 1, 'NO': 0, 'NE': 0, 'SU': 0, 'CO': 0, 'PIBPC': 3.1, 'ESCOL': 3.14, 'ESCOL_NO': 0, 'ESCOL_NE': 0, 'ESCOL_SU': 0, 'ESCOL_CO': 0}\n NE: {'INT': 1, 'NO': 0, 'NE': 1, 'SU': 0, 'CO': 0, 'PIBPC': 3.1, 'ESCOL': 3.14, 'ESCOL_NO': 0, 'ESCOL_NE': 3.14, 'ESCOL_SU': 0, 'ESCOL_CO': 0}\n"
     ]
    }
   ],
   "source": [
    "##Calculando a resposta do item 2C\n",
    "\n",
    "#Chaves para o dicionário\n",
    "Chaves = ['INT','NO','NE','SU','CO','PIBPC','ESCOL','ESCOL_NO','ESCOL_NE','ESCOL_SU','ESCOL_CO']\n",
    "\n",
    "#Vetor de dados para um municipio do SE, sendo o primeiro um valor para o intercepto\n",
    "SE = [1, 0,0,0,0,3.1,3.14,0,0,0,0]\n",
    "SE_dict = dict(zip(Chaves,SE))\n",
    "\n",
    "#Vetor de dados para um municipio do NE, sendo o primeiro um valor para o intercepto\n",
    "NE = [1, 0,1,0,0,3.1,3.14,0,3.14,0,0]\n",
    "NE_dict = dict(zip(Chaves,NE))\n",
    "\n",
    "#Printando os valores pra conferir\n",
    "print(f\"SE: {SE_dict}\\n NE: {NE_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Estimação de SE: 39.02457\n\n    Estimação de NE: 57.78286\n\n    Diferença (SE - NE): -18.75829\n"
     ]
    }
   ],
   "source": [
    "##Fazendo as estimações\n",
    "#np.dot é uma função do numpy que faz um produto interno entre vetores\n",
    "print(f\"\"\"\n",
    "    Estimação de SE: {np.around(np.dot(list(Resultado.params), SE),5)}\\n\n",
    "    Estimação de NE: {np.around(np.dot(list(Resultado.params), NE),5)}\\n\n",
    "    Diferença (SE - NE): {np.around(np.dot(list(Resultado.params), SE) - np.dot(list(Resultado.params), NE),5)}\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'SE': -12.41, 'NO': -10.31, 'SU': -9.76, 'CO': -9.51, 'NE': -8.83}\n"
     ]
    }
   ],
   "source": [
    "## 2d\n",
    "#Os efeitos_educ foram calculados derivando a regressão com relação a educ\n",
    "\n",
    "Regiões = ['SE','NO','SU','CO','NE']\n",
    "Efeitos_Educ = [-12.41,-10.31, -9.76, -9.51, -8.83]\n",
    "Efeitos_Educ_Regiões = dict(zip(Regiões,Efeitos_Educ))\n",
    "\n",
    "print(Efeitos_Educ_Regiões)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisando as desigualdades do SE e do NE, bem como sua escolaridade média e pib per capita médio\n",
    "df_ne = df.loc[df['ne'] == 1]\n",
    "df_se = df.loc[(df['ne'] == 0) & (df['no'] == 0) & (df['su'] == 0) & (df['co'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             escol           pib           pop        desig      pobreza  \\\n",
       "count  1509.000000  1.509000e+03  1.509000e+03  1509.000000  1509.000000   \n",
       "mean      2.006362  7.961412e+04  3.033734e+04     0.537396    68.650024   \n",
       "std       0.825272  6.447999e+05  1.059157e+05     0.108051     9.838807   \n",
       "min       0.400000  3.572565e+02  1.308000e+03     0.185000     2.741000   \n",
       "25%       1.500000  7.455299e+03  8.673000e+03     0.463000    63.771999   \n",
       "50%       1.800000  1.404258e+04  1.501400e+04     0.524000    70.214996   \n",
       "75%       2.300000  2.764470e+04  2.602200e+04     0.593000    75.167999   \n",
       "max       6.900000  1.578945e+07  2.443107e+06     1.174000    89.331001   \n",
       "\n",
       "           poprural        analf        rural        pibpc      ne  ...  \\\n",
       "count   1498.000000  1509.000000  1498.000000  1509.000000  1509.0  ...   \n",
       "mean    9060.873832    42.217346     0.479568     1.261711     1.0  ...   \n",
       "std     7780.458770     9.221081     0.193751     1.497261     0.0  ...   \n",
       "min       34.000000     6.686000     0.000411     0.087306     1.0  ...   \n",
       "25%     3818.000000    37.202000     0.339632     0.743362     1.0  ...   \n",
       "50%     7174.500000    43.060001     0.492068     0.962786     1.0  ...   \n",
       "75%    11907.500000    48.650002     0.624977     1.291097     1.0  ...   \n",
       "max    80139.000000    63.709000     0.984407    32.249939     1.0  ...   \n",
       "\n",
       "           no      escolne  escolse  escolsu  escolco  escolno  escol_no  \\\n",
       "count  1509.0  1509.000000   1509.0   1509.0   1509.0   1509.0    1509.0   \n",
       "mean      0.0     2.006362      0.0      0.0      0.0      0.0       0.0   \n",
       "std       0.0     0.825272      0.0      0.0      0.0      0.0       0.0   \n",
       "min       0.0     0.400000      0.0      0.0      0.0      0.0       0.0   \n",
       "25%       0.0     1.500000      0.0      0.0      0.0      0.0       0.0   \n",
       "50%       0.0     1.800000      0.0      0.0      0.0      0.0       0.0   \n",
       "75%       0.0     2.300000      0.0      0.0      0.0      0.0       0.0   \n",
       "max       0.0     6.900000      0.0      0.0      0.0      0.0       0.0   \n",
       "\n",
       "          escol_ne  escol_su  escol_co  \n",
       "count  1509.000000    1509.0    1509.0  \n",
       "mean      2.006362       0.0       0.0  \n",
       "std       0.825272       0.0       0.0  \n",
       "min       0.400000       0.0       0.0  \n",
       "25%       1.500000       0.0       0.0  \n",
       "50%       1.800000       0.0       0.0  \n",
       "75%       2.300000       0.0       0.0  \n",
       "max       6.900000       0.0       0.0  \n",
       "\n",
       "[8 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>escol</th>\n      <th>pib</th>\n      <th>pop</th>\n      <th>desig</th>\n      <th>pobreza</th>\n      <th>poprural</th>\n      <th>analf</th>\n      <th>rural</th>\n      <th>pibpc</th>\n      <th>ne</th>\n      <th>...</th>\n      <th>no</th>\n      <th>escolne</th>\n      <th>escolse</th>\n      <th>escolsu</th>\n      <th>escolco</th>\n      <th>escolno</th>\n      <th>escol_no</th>\n      <th>escol_ne</th>\n      <th>escol_su</th>\n      <th>escol_co</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1509.000000</td>\n      <td>1.509000e+03</td>\n      <td>1.509000e+03</td>\n      <td>1509.000000</td>\n      <td>1509.000000</td>\n      <td>1498.000000</td>\n      <td>1509.000000</td>\n      <td>1498.000000</td>\n      <td>1509.000000</td>\n      <td>1509.0</td>\n      <td>...</td>\n      <td>1509.0</td>\n      <td>1509.000000</td>\n      <td>1509.0</td>\n      <td>1509.0</td>\n      <td>1509.0</td>\n      <td>1509.0</td>\n      <td>1509.0</td>\n      <td>1509.000000</td>\n      <td>1509.0</td>\n      <td>1509.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.006362</td>\n      <td>7.961412e+04</td>\n      <td>3.033734e+04</td>\n      <td>0.537396</td>\n      <td>68.650024</td>\n      <td>9060.873832</td>\n      <td>42.217346</td>\n      <td>0.479568</td>\n      <td>1.261711</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.006362</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.006362</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.825272</td>\n      <td>6.447999e+05</td>\n      <td>1.059157e+05</td>\n      <td>0.108051</td>\n      <td>9.838807</td>\n      <td>7780.458770</td>\n      <td>9.221081</td>\n      <td>0.193751</td>\n      <td>1.497261</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.825272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.825272</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.400000</td>\n      <td>3.572565e+02</td>\n      <td>1.308000e+03</td>\n      <td>0.185000</td>\n      <td>2.741000</td>\n      <td>34.000000</td>\n      <td>6.686000</td>\n      <td>0.000411</td>\n      <td>0.087306</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.400000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.400000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.500000</td>\n      <td>7.455299e+03</td>\n      <td>8.673000e+03</td>\n      <td>0.463000</td>\n      <td>63.771999</td>\n      <td>3818.000000</td>\n      <td>37.202000</td>\n      <td>0.339632</td>\n      <td>0.743362</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.800000</td>\n      <td>1.404258e+04</td>\n      <td>1.501400e+04</td>\n      <td>0.524000</td>\n      <td>70.214996</td>\n      <td>7174.500000</td>\n      <td>43.060001</td>\n      <td>0.492068</td>\n      <td>0.962786</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.800000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.800000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.300000</td>\n      <td>2.764470e+04</td>\n      <td>2.602200e+04</td>\n      <td>0.593000</td>\n      <td>75.167999</td>\n      <td>11907.500000</td>\n      <td>48.650002</td>\n      <td>0.624977</td>\n      <td>1.291097</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.300000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.300000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.900000</td>\n      <td>1.578945e+07</td>\n      <td>2.443107e+06</td>\n      <td>1.174000</td>\n      <td>89.331001</td>\n      <td>80139.000000</td>\n      <td>63.709000</td>\n      <td>0.984407</td>\n      <td>32.249939</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>6.900000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.900000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_ne.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             escol           pib           pop        desig      pobreza  \\\n",
       "count  1432.000000  1.432000e+03  1.432000e+03  1432.000000  1432.000000   \n",
       "mean      3.804609  3.832703e+05  4.881194e+04     0.500548    30.804546   \n",
       "std       1.020999  4.373650e+06  3.316661e+05     0.097710    16.503420   \n",
       "min       0.800000  2.340898e+03  7.950000e+02     0.290000     2.892000   \n",
       "25%       3.200000  1.405737e+04  5.355500e+03     0.433000    18.491000   \n",
       "50%       3.800000  3.338457e+04  1.150850e+04     0.489500    26.096000   \n",
       "75%       4.400000  1.074550e+05  2.671975e+04     0.554000    39.467251   \n",
       "max       8.800000  1.412110e+08  1.043425e+07     1.062000    78.889999   \n",
       "\n",
       "            poprural        analf        rural        pibpc      ne  ...  \\\n",
       "count    1400.000000  1432.000000  1400.000000  1432.000000  1432.0  ...   \n",
       "mean     4428.149286    17.539379     0.283394     3.966513     0.0  ...   \n",
       "std     17041.200255     8.522155     0.194681     3.182485     0.0  ...   \n",
       "min         7.000000     3.105000     0.000277     0.500990     0.0  ...   \n",
       "25%      1277.500000    11.881250     0.126065     2.158315     0.0  ...   \n",
       "50%      2659.000000    15.410000     0.247807     3.242882     0.0  ...   \n",
       "75%      5079.250000    20.617500     0.416419     4.759246     0.0  ...   \n",
       "max    621065.000000    56.660000     0.856077    50.640675     0.0  ...   \n",
       "\n",
       "           no  escolne      escolse  escolsu  escolco  escolno  escol_no  \\\n",
       "count  1432.0   1432.0  1432.000000   1432.0   1432.0   1432.0    1432.0   \n",
       "mean      0.0      0.0     3.804609      0.0      0.0      0.0       0.0   \n",
       "std       0.0      0.0     1.020999      0.0      0.0      0.0       0.0   \n",
       "min       0.0      0.0     0.800000      0.0      0.0      0.0       0.0   \n",
       "25%       0.0      0.0     3.200000      0.0      0.0      0.0       0.0   \n",
       "50%       0.0      0.0     3.800000      0.0      0.0      0.0       0.0   \n",
       "75%       0.0      0.0     4.400000      0.0      0.0      0.0       0.0   \n",
       "max       0.0      0.0     8.800000      0.0      0.0      0.0       0.0   \n",
       "\n",
       "       escol_ne  escol_su  escol_co  \n",
       "count    1432.0    1432.0    1432.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>escol</th>\n      <th>pib</th>\n      <th>pop</th>\n      <th>desig</th>\n      <th>pobreza</th>\n      <th>poprural</th>\n      <th>analf</th>\n      <th>rural</th>\n      <th>pibpc</th>\n      <th>ne</th>\n      <th>...</th>\n      <th>no</th>\n      <th>escolne</th>\n      <th>escolse</th>\n      <th>escolsu</th>\n      <th>escolco</th>\n      <th>escolno</th>\n      <th>escol_no</th>\n      <th>escol_ne</th>\n      <th>escol_su</th>\n      <th>escol_co</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1432.000000</td>\n      <td>1.432000e+03</td>\n      <td>1.432000e+03</td>\n      <td>1432.000000</td>\n      <td>1432.000000</td>\n      <td>1400.000000</td>\n      <td>1432.000000</td>\n      <td>1400.000000</td>\n      <td>1432.000000</td>\n      <td>1432.0</td>\n      <td>...</td>\n      <td>1432.0</td>\n      <td>1432.0</td>\n      <td>1432.000000</td>\n      <td>1432.0</td>\n      <td>1432.0</td>\n      <td>1432.0</td>\n      <td>1432.0</td>\n      <td>1432.0</td>\n      <td>1432.0</td>\n      <td>1432.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.804609</td>\n      <td>3.832703e+05</td>\n      <td>4.881194e+04</td>\n      <td>0.500548</td>\n      <td>30.804546</td>\n      <td>4428.149286</td>\n      <td>17.539379</td>\n      <td>0.283394</td>\n      <td>3.966513</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.804609</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.020999</td>\n      <td>4.373650e+06</td>\n      <td>3.316661e+05</td>\n      <td>0.097710</td>\n      <td>16.503420</td>\n      <td>17041.200255</td>\n      <td>8.522155</td>\n      <td>0.194681</td>\n      <td>3.182485</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.020999</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.800000</td>\n      <td>2.340898e+03</td>\n      <td>7.950000e+02</td>\n      <td>0.290000</td>\n      <td>2.892000</td>\n      <td>7.000000</td>\n      <td>3.105000</td>\n      <td>0.000277</td>\n      <td>0.500990</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.800000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.200000</td>\n      <td>1.405737e+04</td>\n      <td>5.355500e+03</td>\n      <td>0.433000</td>\n      <td>18.491000</td>\n      <td>1277.500000</td>\n      <td>11.881250</td>\n      <td>0.126065</td>\n      <td>2.158315</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.200000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.800000</td>\n      <td>3.338457e+04</td>\n      <td>1.150850e+04</td>\n      <td>0.489500</td>\n      <td>26.096000</td>\n      <td>2659.000000</td>\n      <td>15.410000</td>\n      <td>0.247807</td>\n      <td>3.242882</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.800000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.400000</td>\n      <td>1.074550e+05</td>\n      <td>2.671975e+04</td>\n      <td>0.554000</td>\n      <td>39.467251</td>\n      <td>5079.250000</td>\n      <td>20.617500</td>\n      <td>0.416419</td>\n      <td>4.759246</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.400000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>8.800000</td>\n      <td>1.412110e+08</td>\n      <td>1.043425e+07</td>\n      <td>1.062000</td>\n      <td>78.889999</td>\n      <td>621065.000000</td>\n      <td>56.660000</td>\n      <td>0.856077</td>\n      <td>50.640675</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.800000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_se.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O valor de LM é 154.634 e seu p-valor é 0.0. Portanto, rejeita-se Ho a um nível de significância de 5.0%.\nHo: O erro é homoscedástico\n"
     ]
    }
   ],
   "source": [
    "Teste_Heteroscedasticidade_White(df[['no','ne','su','co','pibpc','escol','escol_no','escol_ne','escol_su','escol_co']],df['pobreza'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O valor de LM é 381.697 e seu p-valor é 0.0. Portanto, rejeita-se Ho a um nível de significância de 5.0%.\nHo: O erro é homoscedástico\n"
     ]
    }
   ],
   "source": [
    "Teste_Heteroscedasticidade_BP(df[['no','ne','su','co','pibpc','escol','escol_no','escol_ne','escol_su','escol_co']],df['pobreza'])"
   ]
  },
  {
   "source": [
    "# Questão 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "xydata.dta foi lido com sucesso!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             y           x\n",
       "0   459.600006   85.000000\n",
       "1  2048.899902  335.000000\n",
       "2  1587.199951  425.100006\n",
       "3  1540.099976  205.399994\n",
       "4   279.700012   24.299999\n",
       "5   794.200012   55.200001\n",
       "6    38.599998  493.700012\n",
       "7  1600.699951  362.899994\n",
       "8   923.299988   58.500000\n",
       "9  5905.299805  490.100006"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n      <th>x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>459.600006</td>\n      <td>85.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2048.899902</td>\n      <td>335.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1587.199951</td>\n      <td>425.100006</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1540.099976</td>\n      <td>205.399994</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>279.700012</td>\n      <td>24.299999</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>794.200012</td>\n      <td>55.200001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>38.599998</td>\n      <td>493.700012</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1600.699951</td>\n      <td>362.899994</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>923.299988</td>\n      <td>58.500000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5905.299805</td>\n      <td>490.100006</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "coletar_dados(\"xydata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O erro padrão da regressão é 1524.0169 e a SQR é 18581019.99158\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.264\n",
      "Model:                            OLS   Adj. R-squared:                  0.173\n",
      "Method:                 Least Squares   F-statistic:                     2.877\n",
      "Date:                Wed, 18 Nov 2020   Prob (F-statistic):              0.128\n",
      "Time:                        11:26:38   Log-Likelihood:                -86.365\n",
      "No. Observations:                  10   AIC:                             176.7\n",
      "Df Residuals:                       8   BIC:                             177.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        363.5256    833.912      0.436      0.674   -1559.478    2286.529\n",
      "x              4.5528      2.684      1.696      0.128      -1.637      10.743\n",
      "==============================================================================\n",
      "Omnibus:                        6.706   Durbin-Watson:                   1.294\n",
      "Prob(Omnibus):                  0.035   Jarque-Bera (JB):                2.207\n",
      "Skew:                           0.744   Prob(JB):                        0.332\n",
      "Kurtosis:                       4.756   Cond. No.                         538.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Para ver os valores previstos ou os resídudos, basta chamar 'Lista_ychapeu' e 'Resíduos'.\n",
      "Os resultados do modelo podem ser obtidos através de métodos usando a variável 'Resultado'.\n",
      "\n",
      "    Valores de condição maiores que 20 indicam problemas de multicolinearidade\n",
      "    Para ver como achar esse número, entre em https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n"
     ]
    }
   ],
   "source": [
    "#Fazendo uma regressão MQO\n",
    "Regressão_Múltipla(df['x'],df['y'],\"S\",\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O valor de LM é 7.627 e seu p-valor é 0.0220757. Portanto, rejeita-se Ho a um nível de significância de 5.0%.\nHo: O erro é homoscedástico\n"
     ]
    }
   ],
   "source": [
    "#Testando para heteroscedasticidade\n",
    "Teste_Heteroscedasticidade_White(df['x'],df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O erro padrão da regressão é 1524.0169 e a SQR é 18581019.99158\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.264\nModel:                            OLS   Adj. R-squared:                  0.173\nMethod:                 Least Squares   F-statistic:                     1.687\nDate:                Wed, 18 Nov 2020   Prob (F-statistic):              0.230\nTime:                        11:26:39   Log-Likelihood:                -86.365\nNo. Observations:                  10   AIC:                             176.7\nDf Residuals:                       8   BIC:                             177.3\nDf Model:                           1                                         \nCovariance Type:                  HC1                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst        363.5256    433.746      0.838      0.426    -636.694    1363.745\nx              4.5528      3.506      1.299      0.230      -3.531      12.637\n==============================================================================\nOmnibus:                        6.706   Durbin-Watson:                   1.294\nProb(Omnibus):                  0.035   Jarque-Bera (JB):                2.207\nSkew:                           0.744   Prob(JB):                        0.332\nKurtosis:                       4.756   Cond. No.                         538.\n==============================================================================\n\nWarnings:\n[1] Standard Errors are heteroscedasticity robust (HC1)\n\nPara ver os valores previstos ou os resídudos, basta chamar 'Lista_ychapeu' e 'Resíduos'.\nOs resultados do modelo podem ser obtidos através de métodos usando a variável 'Resultado'.\n\n    Valores de condição maiores que 20 indicam problemas de multicolinearidade\n    Para ver como achar esse número, entre em https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n"
     ]
    }
   ],
   "source": [
    "#Usando erros padrões robustos\n",
    "Regressão_Múltipla(df['x'],df['y'],\"S\",\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "O erro padrão da regressão é 1552.04793 e a SQR é 19270822.33721\n\n                            WLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.529\nModel:                            WLS   Adj. R-squared:                  0.470\nMethod:                 Least Squares   F-statistic:                     8.986\nDate:                Wed, 18 Nov 2020   Prob (F-statistic):             0.0171\nTime:                        11:26:39   Log-Likelihood:                -79.333\nNo. Observations:                  10   AIC:                             162.7\nDf Residuals:                       8   BIC:                             163.3\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst        226.1160    120.522      1.876      0.097     -51.808     504.040\nx              5.7197      1.908      2.998      0.017       1.320      10.120\n==============================================================================\nOmnibus:                        1.222   Durbin-Watson:                   1.861\nProb(Omnibus):                  0.543   Jarque-Bera (JB):                0.781\nSkew:                           0.329   Prob(JB):                        0.677\nKurtosis:                       1.800   Cond. No.                         84.5\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nPara ver os valores previstos ou os resídudos, basta chamar 'Lista_ychapeu' e 'Resíduos'.\nOs resultados do modelo podem ser obtidos através de métodos usando a variável 'Resultado'.\n\n    Valores de condição maiores que 20 indicam problemas de multicolinearidade\n    Para ver como achar esse número, entre em https://www.statsmodels.org/dev/examples/notebooks/generated/ols.html\n"
     ]
    }
   ],
   "source": [
    "#Usando MQP\n",
    "df['x2'] = df['x']**2\n",
    "Regressão_MQP(df['x'],df['y'],1/df['x2'],\"S\",\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}